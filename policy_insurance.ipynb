{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a3aa0e",
   "metadata": {},
   "source": [
    " DOCUMENT PARSER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f7f324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "def parseText(pdf_path):\n",
    "    \"\"\"Parse PDF and split into chunks\"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    policy_text = \"\"\n",
    "\n",
    "    for page_num, page in enumerate(reader.pages, start=1):\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            policy_text += f\"\\n\\n[Page {page_num}]\\n{text}\"\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=400,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    return splitter.split_text(policy_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c160d76",
   "metadata": {},
   "source": [
    "SEMANTIC SEARCH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ce5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def build_index(chunks):\n",
    "    \"\"\"Build FAISS index for semantic search\"\"\"\n",
    "    embeddings = embed_model.encode(chunks)\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(np.array(embeddings))\n",
    "    return index\n",
    "\n",
    "def searchText(question, chunks, index, top_k=3):\n",
    "    \"\"\"Retrieve relevant chunks from the policy\"\"\"\n",
    "    q_embedding = embed_model.encode([question])\n",
    "    _, indices = index.search(q_embedding, top_k)\n",
    "    return \"\\n\".join([chunks[i] for i in indices[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54156c8",
   "metadata": {},
   "source": [
    "POLICY DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4574a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyDatabase:\n",
    "    \"\"\"Stores policy chunks and FAISS index\"\"\"\n",
    "    def __init__(self, chunks):\n",
    "        self.chunks = chunks\n",
    "        self.index = build_index(chunks)\n",
    "\n",
    "    def query(self, question):\n",
    "        return searchText(question, self.chunks, self.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb813d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyText(question):\n",
    "    \"\"\"Simple keyword-based intent classification\"\"\"\n",
    "    question_lower = question.lower()\n",
    "    if \"rent\" in question_lower:\n",
    "        return \"room_rent\"\n",
    "    elif \"claim\" in question_lower:\n",
    "        return \"claims\"\n",
    "    return \"general\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e88c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "model_name = \"Qwen/Qwen2-1.5B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6dc618",
   "metadata": {},
   "source": [
    "TOOL CALLING CONTROLLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7cac1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_router(question):\n",
    "    \"\"\"Decide which tool to use based on question\"\"\"\n",
    "    # Here we can integrate classifyText for simplicity\n",
    "    intent = classifyText(question)\n",
    "    if intent == \"room_rent\" or intent == \"claims\" or intent == \"general\":\n",
    "        return \"PolicyDatabase.query\"\n",
    "    return \"PolicyDatabase.query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cdc6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeText(context, question):\n",
    "    \"\"\"Generate a simple, clear answer using the context\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are an insurance policy assistant.\n",
    "\n",
    "\n",
    "STRICT RULES:\n",
    "- Use ONLY the policy context below\n",
    "- If numbers or limits are present, you MUST quote them exactly\n",
    "- If the answer exists, DO NOT say \"not specified\"\n",
    "- If the answer does NOT exist, say:\n",
    "  \"The policy does not explicitly mention this information.\"\n",
    "\n",
    "Explain in simple language.\n",
    "Policy Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(**inputs, max_new_tokens=200)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04ae9777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayInformation(answer):\n",
    "    print(\"\\nAnswer:\\n\")\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b1a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Selected by LLM: PolicyDatabase.query\n",
      "\n",
      "Answer:\n",
      "\n",
      "\n",
      "You are an insurance policy assistant.\n",
      "\n",
      "\n",
      "STRICT RULES:\n",
      "- Use ONLY the policy context below\n",
      "- If numbers or limits are present, you MUST quote them exactly\n",
      "- If the answer exists, DO NOT say \"not specified\"\n",
      "- If the answer does NOT exist, say:\n",
      "  \"The policy does not explicitly mention this information.\"\n",
      "\n",
      "Explain in simple language.\n",
      "Policy Context:\n",
      "8. Ambulance Expenses:  1% of Sum Insured per Policy period up to a maximum of INR 1500 will be reimbursed \n",
      "to Insured  for the cost of ambulance transportation.  Ambulance services used should be of a licensed \n",
      "ambulance operator. \n",
      " \n",
      "9. Ayurvedic Medicine: Ayurvedic Treatment covered up to maximum 15% of Sum Insured per Policy Period\n",
      "restricted maximum up to 25% of the Sum Insured per illness/injury. \n",
      " \n",
      "2. Medical Practitioner , Surgeon, Anesthetist, Consultants, and Specialists Fees - All admissible claims under \n",
      "this section during the policy period restricted maximum up to 40% of the Sum Insured per illness/injury. \n",
      " \n",
      "3. Anesthesia, Blood, Oxygen, Operation Theatre Expens es, Surgical Appliances, Medicines & consumables,\n",
      "6. Post-Hospitalisation Expenses:  The maximum amount that can be claimed under this head is limited to \n",
      "10% of the Eligible Hospitalisation Expenses  for each of the admitted hosipitalisation claim un der the \n",
      "Policy. \n",
      " \n",
      "7. Day Care Expenses:  Insurer  shall pay for Day Care Expenses incurred on techno logical surgeries and\n",
      "\n",
      "Question:\n",
      "How much ambulance expense is covered?\n",
      "\n",
      "Answer:\n",
      "Under the insurance policy, the insurer will cover up to a maximum of INR 1500 for the cost of ambulance transportation as part of the Sum Insured per Policy period. This reimbursement is subject to the condition that the ambulance services used should be of a licensed ambulance operator.\n",
      "\n",
      "For Ayurvedic Medicine, the insurer covers up to a maximum of 15% of the Sum Insured per Policy Period for all illnesses and injuries. However, there is a restriction with respect to the maximum allowed coverage, which is up to 25% of the Sum Insured per illness/injury.\n",
      "\n",
      "In terms of medical practitioner fees, the insurer covers up to 40% of the Sum Insured per illness/injury under this section.\n",
      "\n",
      "Anesthesia, blood, oxygen, operation theatre expenses, surgical appliances, medicines, and consumables are also covered under the insurance policy. These expenses are capped at 10% of the eligible hospitalization expenses for each admitted hospitalization claim under\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    chunks = parseText(\"policy.pdf\")\n",
    "\n",
    "    policy_db = PolicyDatabase(chunks)\n",
    "\n",
    "    question = \"How much ambulance expense is covered?\"\n",
    "\n",
    "    tool_used = tool_router(question)\n",
    "    print(\"Tool Selected by LLM:\", tool_used)\n",
    "\n",
    "    if tool_used == \"PolicyDatabase.query\":\n",
    "        context = policy_db.query(question)\n",
    "    else:\n",
    "        context = \"No relevant tool found.\"\n",
    "    answer = summarizeText(context, question)\n",
    "    displayInformation(answer)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b581e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
