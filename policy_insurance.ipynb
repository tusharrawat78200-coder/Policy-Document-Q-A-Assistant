{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a3aa0e",
   "metadata": {},
   "source": [
    " DOCUMENT PARSER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f7f324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "def parseText(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    policy_text = \"\"\n",
    "\n",
    "    for page_num, page in enumerate(reader.pages, start=1):\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            policy_text += f\"\\n\\n[Page {page_num}]\\n{text}\"\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=400,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    return splitter.split_text(policy_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c160d76",
   "metadata": {},
   "source": [
    "SEMANTIC SEARCH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ce5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def build_index(chunks):\n",
    "    \"\"\"Build FAISS index for semantic search\"\"\"\n",
    "    embeddings = embed_model.encode(chunks)\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(np.array(embeddings))\n",
    "    return index\n",
    "\n",
    "def searchText(question, chunks, index, top_k=3):\n",
    "    \"\"\"Retrieve relevant chunks from the policy\"\"\"\n",
    "    q_embedding = embed_model.encode([question])\n",
    "    _, indices = index.search(q_embedding, top_k)\n",
    "    return \"\\n\".join([chunks[i] for i in indices[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54156c8",
   "metadata": {},
   "source": [
    "POLICY DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4574a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyDatabase:\n",
    "    \"\"\"Stores policy chunks and FAISS index\"\"\"\n",
    "    def __init__(self, chunks):\n",
    "        self.chunks = chunks\n",
    "        self.index = build_index(chunks)\n",
    "\n",
    "    def query(self, question):\n",
    "        return searchText(question, self.chunks, self.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb813d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyText(question):\n",
    "    \"\"\"Simple keyword-based intent classification\"\"\"\n",
    "    question_lower = question.lower()\n",
    "    if \"rent\" in question_lower:\n",
    "        return \"room_rent\"\n",
    "    elif \"claim\" in question_lower:\n",
    "        return \"claims\"\n",
    "    return \"general\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e88c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "model_name = \"Qwen/Qwen2-1.5B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6dc618",
   "metadata": {},
   "source": [
    "TOOL CALLING CONTROLLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7cac1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_router(question):\n",
    "    \"\"\"Decide which tool to use based on question\"\"\"\n",
    "    # Here we can integrate classifyText for simplicity\n",
    "    intent = classifyText(question)\n",
    "    if intent == \"room_rent\" or intent == \"claims\" or intent == \"general\":\n",
    "        return \"PolicyDatabase.query\"\n",
    "    return \"PolicyDatabase.query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cdc6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeText(context, question):\n",
    "    \"\"\"Generate a simple, clear answer using the context\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are an insurance policy assistant.\n",
    "\n",
    "STRICT RULES:\n",
    "- Use ONLY the provided policy context.\n",
    "- DO NOT assume or guess.\n",
    "- DO NOT add disclaimers, notes, or recommendations.\n",
    "- Answer ONLY what is asked.\n",
    "- If the answer is not explicitly stated, say:\n",
    "  \"The policy does not explicitly mention this information.\"\n",
    "\n",
    "Policy Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    inputs =tokenizer(prompt,return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=120,\n",
    "        do_sample=False,\n",
    "        temperature=0.0,\n",
    "        top_p=1.0\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "\n",
    "    answer=full_text.split(\"Answer:\")[-1].strip()\n",
    "\n",
    "    return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04ae9777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayInformation(answer):\n",
    "    print(\"\\nAnswer:\\n\")\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a4b1a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Selected by LLM: PolicyDatabase.query\n",
      "\n",
      "Answer:\n",
      "\n",
      "\n",
      "You are an insurance policy assistant.\n",
      "\n",
      "STRICT RULES:\n",
      "- Use ONLY the provided policy context.\n",
      "- DO NOT assume or guess.\n",
      "- DO NOT add disclaimers, notes, or recommendations.\n",
      "- Answer ONLY what is asked.\n",
      "- If the answer is not explicitly stated, say:\n",
      "  \"The policy does not explicitly mention this information.\"\n",
      "\n",
      "Policy Context:\n",
      "8. Ambulance Expenses:  1% of Sum Insured per Policy period up to a maximum of INR 1500 will be reimbursed \n",
      "to Insured  for the cost of ambulance transportation.  Ambulance services used should be of a licensed \n",
      "ambulance operator. \n",
      " \n",
      "9. Ayurvedic Medicine: Ayurvedic Treatment covered up to maximum 15% of Sum Insured per Policy Period\n",
      "restricted maximum up to 25% of the Sum Insured per illness/injury. \n",
      " \n",
      "2. Medical Practitioner , Surgeon, Anesthetist, Consultants, and Specialists Fees - All admissible claims under \n",
      "this section during the policy period restricted maximum up to 40% of the Sum Insured per illness/injury. \n",
      " \n",
      "3. Anesthesia, Blood, Oxygen, Operation Theatre Expens es, Surgical Appliances, Medicines & consumables,\n",
      "6. Post-Hospitalisation Expenses:  The maximum amount that can be claimed under this head is limited to \n",
      "10% of the Eligible Hospitalisation Expenses  for each of the admitted hosipitalisation claim un der the \n",
      "Policy. \n",
      " \n",
      "7. Day Care Expenses:  Insurer  shall pay for Day Care Expenses incurred on techno logical surgeries and\n",
      "\n",
      "Question:\n",
      "How much ambulance expense is covered?\n",
      "\n",
      "Answer:\n",
      "INR 1500\n",
      "\n",
      "Please note that the policy context mentions that the maximum reimbursement for ambulance expenses is 1% of the sum insured per policy period, but it also specifies that only licensed ambulance operators should be used. Additionally, the policy covers ayurvedic treatment up to 15% of the sum insured per policy period, medical practitioner fees up to 40% of the sum insured per illness/injury, anesthesia, blood, oxygen, operation theatre expenses, surgical appliances, medicines, and consumables, and post-hospitalization expenses up to 10% of\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    chunks = parseText(\"policy.pdf\")\n",
    "\n",
    "    policy_db = PolicyDatabase(chunks)\n",
    "\n",
    "    question = \"How much ambulance expense is covered?\"\n",
    "\n",
    "    tool_used = tool_router(question)\n",
    "    print(\"Tool Selected by LLM:\", tool_used)\n",
    "\n",
    "    if tool_used == \"PolicyDatabase.query\":\n",
    "        context = policy_db.query(question)\n",
    "    else:\n",
    "        context = \"No relevant tool found.\"\n",
    "    answer = summarizeText(context, question)\n",
    "    displayInformation(answer)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe3b209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b581e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
